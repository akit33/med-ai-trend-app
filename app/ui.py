# app/ui.py (Streamlit UI - ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰)

import streamlit as st
import pandas as pd
import requests
import plotly.graph_objects as go
from app.mesh_trend import get_top_terms 
import os
from dotenv import load_dotenv

# ==============================================================================
# I. åˆæœŸè¨­å®šã¨ãƒ‘ã‚¹å®šç¾©
# ==============================================================================

load_dotenv(dotenv_path='../.env') # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(BASE_DIR, "../pubmed_articles_details.csv")

# FastAPI ã® URL ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆ)
API_URL = os.getenv("API_URL", "http://127.0.0.1:8000/predict")

# ====  ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³  ====
st.sidebar.title("åŒ»ç™‚ AI æ–‡çŒ®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¢ãƒ—ãƒª")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒ¢ãƒ¼ãƒ‰ã‚’ä¿å­˜
if "mode" not in st.session_state:
    st.session_state["mode"] = "æ–‡çŒ®æ•°äºˆæ¸¬"

# ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ“ˆ æ–‡çŒ®æ•°äºˆæ¸¬ (æ™‚ç³»åˆ—äºˆæ¸¬)"):
    st.session_state["mode"] = "æ–‡çŒ®æ•°äºˆæ¸¬"
if st.sidebar.button("ğŸ” ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ (ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°/TF-IDF)"):
    st.session_state["mode"] = "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰"
    
mode = st.session_state["mode"]

# ==============================================================================
# II. æ–‡çŒ®æ•°äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ (æ™‚ç³»åˆ—äºˆæ¸¬ã®çµæœè¡¨ç¤º)
# ==============================================================================

if mode == "æ–‡çŒ®æ•°äºˆæ¸¬":
    st.header("ğŸ“ˆ åŒ»ç™‚ AI æ–‡çŒ®æ•°äºˆæ¸¬")
    st.markdown("ä»»æ„ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸ**ç‰¹å®šã®ãƒˆãƒ¬ãƒ³ãƒ‰**ã¨**åŒ»ç™‚ AI å…¨ä½“**ã®æ–‡çŒ®æ•°ã®æ¨ç§»ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ã‚’ 1 è¡Œã«ä¸¦ã¹ã‚‹ (UXã®å‘ä¸Š)
    st.write("ä»»æ„ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æœ€å¤§ 3 ã¤å…¥åŠ›ã—ã¦ãã ã•ã„")
    col1, col2, col3 = st.columns(3)
    with col1:
        keyword1 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 1", label_visibility="collapsed", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 1")
    with col2:
        keyword2 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 2", label_visibility="collapsed", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 2")
    with col3:
        keyword3 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 3", label_visibility="collapsed", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ 3")
        
    keywords = [k for k in [keyword1, keyword2, keyword3] if k]

    if st.button("äºˆæ¸¬å®Ÿè¡Œ"):
        if not keywords:
            st.warning("ğŸš¨ å°‘ãªãã¨ã‚‚ 1 ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("â³ äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­..."):
                try:
                    # FastAPI ãƒ«ãƒ¼ã‚¿ãƒ¼ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
                    response = requests.post(API_URL, json={"keywords": keywords})
                    response.raise_for_status() # 4xx/5xx ã‚¨ãƒ©ãƒ¼ã‚’æ•æ‰
                    result = response.json()
                    
                    st.success("âœ… äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                    # ---  ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º  ---
                    all_past_counts = result["all_past_literature_counts"]
                    all_predicted_counts = result["all_predicted_literature_counts"]
                    all_past_end_date_str = result["all_past_end_date"]
                    keyword_past_counts = result["keyword_past_literature_counts"]
                    keyword_predicted_counts = result["keyword_predicted_literature_counts"]
                    keyword_past_end_date_str = result["keyword_past_end_date"]
                    
                    # ---  æ—¥ä»˜ç¯„å›²ã®ç”Ÿæˆ (å¯è¦–åŒ–ã®ãŸã‚ã«å¿…é ˆ)  ---
                    # äºˆæ¸¬æœŸé–“ã®æ—¥ä»˜ç¯„å›²ã‚’æ­£ç¢ºã«ä½œæˆ
                    def generate_dates(past_end_date_str, past_counts, predicted_counts):
                        past_dates = pd.date_range(start=pd.to_datetime(past_end_date_str) - pd.DateOffset(months=len(past_counts)-1), end=past_end_date_str, freq="MS")
                        predicted_start_date = pd.to_datetime(past_end_date_str) + pd.DateOffset(months=1)
                        predicted_dates = pd.date_range(start=predicted_start_date, periods=len(predicted_counts), freq="MS")
                        return past_dates, predicted_dates

                    keyword_past_dates, keyword_predicted_dates = generate_dates(
                        keyword_past_end_date_str, keyword_past_counts, keyword_predicted_counts)
                    all_past_dates, all_predicted_dates = generate_dates(
                        all_past_end_date_str, all_past_counts, all_predicted_counts)
                    
                    # --- 1 ã¤ã® Plotly Figure ã«çµ±åˆ  ---
                    st.markdown("<h4 style='margin-bottom:5px;'>æ–‡çŒ®æ²è¼‰æ•°ã®æ¨ç§» (å®Ÿç¸¾ã¨äºˆæ¸¬)</h4>", unsafe_allow_html=True)
                    fig = go.Figure()
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç³»åˆ— (å®Ÿç¸¾ - å®Ÿç·š / äºˆæ¸¬ - ç ´ç·š)
                    fig.add_trace(go.Scatter(
                        x=keyword_past_dates, y=keyword_past_counts,
                        mode='lines+markers', name=f'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {", ".join(keywords)} (å®Ÿç¸¾)', line=dict(color='blue')
                    ))
                    fig.add_trace(go.Scatter(
                        x=keyword_predicted_dates, y=keyword_predicted_counts,
                        mode='lines+markers', name='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (äºˆæ¸¬)', line=dict(color='red', dash='dash') # äºˆæ¸¬ã¯ç ´ç·šã§æ˜ç¢ºåŒ–
                    ))
                    
                    # å…¨æ–‡çŒ®ç³»åˆ— (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)
                    fig.add_trace(go.Scatter(
                        x=all_past_dates, y=all_past_counts,
                        mode='lines', name='åŒ»ç™‚ AI æ–‡çŒ®å…¨ä½“ (å®Ÿç¸¾)', line=dict(color='gray')
                    ))
                    fig.add_trace(go.Scatter(
                        x=all_predicted_dates, y=all_predicted_counts,
                        mode='lines', name='åŒ»ç™‚ AI æ–‡çŒ®å…¨ä½“ (äºˆæ¸¬)', line=dict(color='orange', dash='dot') # äºˆæ¸¬ã¯ç‚¹ç·šã§æ˜ç¢ºåŒ–
                    ))

                    fig.update_layout(
                        xaxis_title='å¹´æœˆ',
                        yaxis_title='æ²è¼‰æ–‡çŒ®æ•°',
                        template='plotly_white',
                        legend=dict(x=0, y=1, bgcolor='rgba(0,0,0,0)'),
                        margin=dict(t=30, l=50, r=30, b=50)
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ---  ã‚µãƒãƒªãƒ¼ã¨äºˆæ¸¬å€¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«  ---
                    extracted_articles_count = result["extracted_articles_count"]
                    st.markdown(
                        f"<h4 style='margin-bottom:10px;'>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åˆè‡´ã™ã‚‹æ–‡çŒ®ã®éå»æ²è¼‰æ•°: {extracted_articles_count} ä»¶ </h4>",
                        unsafe_allow_html=True
                    )
                    
                    df_pred = pd.DataFrame([keyword_predicted_counts],
                                            columns=[d.strftime("%Y-%m") for d in keyword_predicted_dates],
                                            index=["æ²è¼‰æ•°"])
                    df_pred = df_pred.round(0).astype(int)
                    
                    st.markdown("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ–‡çŒ®ã®äºˆæ¸¬å€¤ï¼ˆæœˆã”ã¨ï¼‰", unsafe_allow_html=True)
                    st.dataframe(df_pred.T) # ç¸¦å‘ãã«å¤‰æ›ã—ã¦ Streamlit ã®æ¨™æº–ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¡¨ç¤º
                    
                except requests.exceptions.RequestException as e:
                    st.error(f"âŒ APIæ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ (FastAPI/pt_worker) ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„: {e}")
                except Exception as e:
                    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ==============================================================================
# III. ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ (åˆ†æçµæœã®è¡¨ç¤º)
# ==============================================================================

elif mode == "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰":
    st.header("ğŸ” ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰è§£æ")
    st.info("MeSH ç”¨èªã®ä½¿ç”¨ç‡ã®ä¼¸ã³ã€ãŠã‚ˆã³ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æŠ„éŒ²ã® TF-IDF é »å‡ºèªã‚’è§£æã—ã¾ã™ã€‚")
    
    if not os.path.exists(CSV_PATH):
        st.error(f"ğŸš¨ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CSV_PATH}ã€‚ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
    else:
        # ====  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š  ====
        # è¡¨ç¤ºæ•°ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¤‰æ›´å¯èƒ½ã«ã™ã‚‹
        top_n = st.slider("è¡¨ç¤ºã™ã‚‹ä¸Šä½èªæ•°", 10, 50, 20, step=5)
        last_n = st.slider("æ¯”è¼ƒã™ã‚‹æœˆæ•° (ç›´è¿‘ N ãƒ¶æœˆ vs ãã®å‰ N ãƒ¶æœˆ)", 6, 24, 12, step=6)
        
        # ====  è¡¨ç¤ºãƒœã‚¿ãƒ³  ====
        if st.button("è§£æå®Ÿè¡Œ"):
            with st.spinner("â³ å¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­..."):
                try:
                    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® CSV ãƒ‘ã‚¹ã‚’æ¸¡ã™
                    growth, clusters, usage, keyword_growth = get_top_terms(
                        CSV_PATH, top_n=top_n, last_n=last_n
                    )
                    
                    st.success("âœ… è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                    # 1. MeSH ç”¨èªã®ä¼¸ã³ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
                    st.subheader("1. ä¼¸ã³ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (MeSH Terms)")
                    st.markdown("ç›´è¿‘æœŸé–“ã®ä½¿ç”¨ç‡ã®**çµ¶å¯¾å¢—åŠ é‡**ãŒå¤§ãã„é †ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¾ã—ãŸã€‚")
                    
                    # å¿…è¦ãªåˆ—ã®ã¿ã‚’æ•´ç†ã—ã¦è¡¨ç¤º
                    growth_display = growth.head(top_n).reset_index().rename(
                        columns={'index': 'MeSH ã‚¿ãƒ¼ãƒ ', 'abs_increase': 'çµ¶å¯¾å¢—åŠ é‡', 'rel_increase': 'ç›¸å¯¾å¢—åŠ ç‡', 'slope': 'ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰å‚¾ã'}
                    )
                    st.dataframe(growth_display.style.format(precision=4))
                    
                    # 2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
                    st.subheader(f"2. MeSH ç”¨èªã® KMeans ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°: {len(clusters['cluster'].unique())})")
                    st.markdown("ç”¨èªã®ä½¿ç”¨ç‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ™‚ç³»åˆ—ã§åˆ†é¡ã—ã¾ã—ãŸã€‚")
                    
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã¨å¹³å‡ä¼¸ã³ç‡ã‚’çµåˆã—ã¦è¡¨ç¤º
                    clustered_growth = pd.merge(growth, clusters, on='term').reset_index(drop=True)
                    clustered_growth_display = clustered_growth[['term', 'cluster', 'abs_increase', 'rel_increase']].sort_values('cluster')
                    st.dataframe(clustered_growth_display.rename(columns={'term': 'MeSH ã‚¿ãƒ¼ãƒ ', 'cluster': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ID'}))
                    
                    # 3. TF-IDF é »å‡ºèªãƒ©ãƒ³ã‚­ãƒ³ã‚°
                    st.subheader("3. ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æŠ„éŒ² TF-IDF é »å‡ºèªãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                    st.markdown("MeSH ç”¨èªãƒªã‚¹ãƒˆã¨ã‚¯ãƒ­ã‚¹å‚ç…§ã—ã€åŒ»ç™‚ AI é–¢é€£åº¦ã®é«˜ã„é »å‡ºèªã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™ã€‚")
                    
                    keyword_growth_display = keyword_growth.head(top_n).reset_index().rename(
                        columns={'index': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'abs_increase': 'çµ¶å¯¾å¢—åŠ é‡', 'recent_mean': 'ç›´è¿‘å¹³å‡ä½¿ç”¨ç‡'}
                    )
                    st.dataframe(keyword_growth_display.style.format(precision=4))

                except Exception as e:
                    st.error(f"âŒ è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")